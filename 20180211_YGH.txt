머신러닝 - 일종의 소프트웨어
명시적 프로그래밍은 한계가 있음 --> 머신러닝 : 프로그램 자체가 어떤 데이터를 보고 학습해서 뭔가를 배우는 능력을 가진 프로그램

supervised learning : 정해져있는(label된) 데이터를 가지고 학습을 하는 것,예측,2진분류,multi-label 분류
unsupervised learning : un-labeled data

-----------------------------------
Linear Regression

input을 이용하여 선형 가설을 세움   y=H(x)=Wx + b 
Cost function ==> 일반적으로 {H(x)-y}^2  ==> 제곱을 하는 이유 : 차이가 음이든 양이든 양수로 표현가능, 차이가 클 수록 더 큰 페널티를 줄 수 있음

H(x)=Wx+b ==> H(x)=Wx
cost(W,b) ==> cost(W)  = 1/m 시그마(Wxi - yi)^2
H(x1,x2,x3) = w1x1+w2x2+w3x3+b   ===> 행렬 연산으로 처리

HCG : Hypothesis, Cost, Gradient decent(경사내려가기 알고리즘?)
Hypothesis : H(x)=Wx
Cost : cost(W)=1/m 시그마(Wx - y)^2
Gradient decent : W := W -알파*W에대한미분*cost(W)    ==> 알파 = learning_rate

classification ==> 0,1로 인코딩 함 ==> Linear Regression에서도 중간값을 기준으로 이분법함
z=Wx, H(x)=g(z) ==> 새로운 함수를 만들어 0~1 사이의 값이 나오도록 함

Overfitting ==> 만든 모델이 traning dataset에 너무 잘맞아서 복잡한 경우
==> 해결방안 : Regularization

---------------------------------------
XOR 문제 : OR나 AND는 구분하는 것을 Linear하게 잘 동작하는데 XOR은 안됨

==>1969년에 수학적으로 교수가 불가능하다고 발표 ==>그래서 인공지능 침체기
==>10~20년 후 해결 Backpropagation , Ouput부터 Input까지 거꾸로 올라가며 에러보정 

Convolutional Neural Networks ==>>여러가지 동시에 구성해서 90%이상 달성 

==>큰문제 대두 : 중간단계가 너무 많을 경우 멀리 떨어진 W와 b 제어 불가능 ==> 다시 침체기

